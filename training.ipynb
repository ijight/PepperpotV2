{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "new_working_directory = \"C:\\\\Users\\\\ianja\\\\REPOS\\\\Pepperpot\\\\\"\n",
    "os.chdir(new_working_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\ianja\\REPOS\\Pepperpot\n",
      "The directory 'local-images-before-after-propagation-bw-shorter' exists.\n",
      "Image organization completed.\n"
     ]
    }
   ],
   "source": [
    "# SEGMENT A DIR BY PARAM VARIATION\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "class ParameterValues:\n",
    "    def __init__(self, epsnx, alfax, betax, epsny, alfay, betay, epsnz, alfaz, betaz):\n",
    "        self.epsnx = epsnx\n",
    "        self.alfax = alfax\n",
    "        self.betax = betax\n",
    "        self.epsny = epsny\n",
    "        self.alfay = alfay\n",
    "        self.betay = betay\n",
    "        self.epsnz = epsnz\n",
    "        self.alfaz = alfaz\n",
    "        self.betaz = betaz\n",
    "\n",
    "# Specify the local directory containing the images\n",
    "local_directory = 'local-images-before-after-propagation-bw-shorter'\n",
    "\n",
    "# Check the current working directory\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Check if the local_directory exists in the current working directory\n",
    "if not os.path.exists(local_directory):\n",
    "    print(f\"The directory '{local_directory}' does not exist in the current working directory.\")\n",
    "else:\n",
    "    print(f\"The directory '{local_directory}' exists.\")\n",
    "\n",
    "# Create the target directories for organizing the images\n",
    "target_directory_2param = os.path.join(local_directory, '2-param')\n",
    "target_directory_3param = os.path.join(local_directory, '3-param')\n",
    "target_directory_6param = os.path.join(local_directory, '6-param')\n",
    "\n",
    "# Create the target directories if they don't exist\n",
    "os.makedirs(target_directory_2param, exist_ok=True)\n",
    "os.makedirs(target_directory_3param, exist_ok=True)\n",
    "os.makedirs(target_directory_6param, exist_ok=True)\n",
    "\n",
    "# Regular expression pattern for extracting parameters from filename\n",
    "pattern = r\"epsnx([\\d.-]+)_alfax([\\d.-]+)_betax([\\d.-]+)_epsny([\\d.-]+)_alfay([\\d.-]+)_betay([\\d.-]+)_epsnz([\\d.-]+)_alfaz([\\d.-]+)_betaz([\\d.-]+)_*[\\d]*\\.png\"\n",
    "\n",
    "# Iterate over the images in the local directory\n",
    "for filename in os.listdir(local_directory):\n",
    "    if filename.endswith('.png'):\n",
    "        source_path = os.path.join(local_directory, filename)\n",
    "\n",
    "        # Extract parameters from filename using regex\n",
    "        match = re.match(pattern, filename)\n",
    "        if match:\n",
    "            params = ParameterValues(*match.groups())\n",
    "            varied_params = sum(param != '0.0' for param in vars(params).values())\n",
    "\n",
    "            # Move the file to the corresponding target directory based on the number of varied parameters\n",
    "            if filename.startswith(\"epsnx0.1_\"):\n",
    "                target_path = os.path.join(target_directory_2param, filename)\n",
    "            elif params.alfay == \"-0.55\" and params.betay == \"170.0\":\n",
    "                target_path = os.path.join(target_directory_3param, filename)\n",
    "            else:\n",
    "                target_path = os.path.join(target_directory_6param, filename)\n",
    "\n",
    "            shutil.move(source_path, target_path)\n",
    "\n",
    "print(\"Image organization completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST/TRAIN SPLIT\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "original_folders = [\"local-images-50cm-propagation-bw-200bin-cropped/2-param/\", \"local-images-50cm-propagation-bw-200bin-cropped/3-param/\", \"local-images-10cm-propagation-bw-200bin-cropped\"]\n",
    "train_folder = \"./train\"\n",
    "test_folder = \"./test\"\n",
    "\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "train_ratio = 0.8\n",
    "\n",
    "file_list = []\n",
    "\n",
    "for folder in original_folders:\n",
    "    file_list.extend([os.path.join(folder, file) for file in os.listdir(folder)])\n",
    "    print(len(file_list))\n",
    "\n",
    "random.shuffle(file_list)\n",
    "\n",
    "train_size = int(len(file_list) * train_ratio)\n",
    "\n",
    "train_files = file_list[:train_size]\n",
    "test_files = file_list[train_size:]\n",
    "\n",
    "for src_path in train_files:\n",
    "    file = os.path.basename(src_path)\n",
    "    dst_path = os.path.join(train_folder, file)\n",
    "\n",
    "    # Check if a file with the same name already exists in the target directory\n",
    "    if os.path.exists(dst_path):\n",
    "        # Split filename into name and extension\n",
    "        base, ext = os.path.splitext(file)\n",
    "        # Append a unique identifier to the filename\n",
    "        new_filename = f\"{base}_{random.randint(1000,9999)}{ext}\"\n",
    "        dst_path = os.path.join(train_folder, new_filename)\n",
    "\n",
    "    shutil.copy(src_path, dst_path)\n",
    "\n",
    "for src_path in test_files:\n",
    "    file = os.path.basename(src_path)\n",
    "    dst_path = os.path.join(test_folder, file)\n",
    "\n",
    "    # Check if a file with the same name already exists in the target directory\n",
    "    if os.path.exists(dst_path):\n",
    "        # Split filename into name and extension\n",
    "        base, ext = os.path.splitext(file)\n",
    "        # Append a unique identifier to the filename\n",
    "        new_filename = f\"{base}_{random.randint(1000,9999)}{ext}\"\n",
    "        dst_path = os.path.join(test_folder, new_filename)\n",
    "\n",
    "    shutil.copy(src_path, dst_path)\n",
    "\n",
    "print(\"Dataset split completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# force clear cache and memory\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import random\n",
    "\n",
    "# ensure determinism\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-PARAMETER SIDE_BY_SIDE MODEL \n",
    "NAME = \"3param-dbwd\"\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 197 * 98, 256)  # Adjusted input size\n",
    "        self.fc2 = nn.Linear(256, 2) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB for DOUBLE WIDE IMAGE\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_files):\n",
    "        self.image_files = image_files\n",
    "        self.pattern = r\"epsnx([\\d.-]+)_alfax([\\d.-]+)_betax([\\d.-]+)_epsny([\\d.-]+)_alfay([\\d.-]+)_betay([\\d.-]+)_epsnz([\\d.-]+)_alfaz([\\d.-]+)_betaz([\\d.-]+)_*[\\d]*\\.png\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_files[index]\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (394, 197)).astype(np.float32) / 255.0\n",
    "\n",
    "        # add dummy dim (1, x, x)\n",
    "        image = np.expand_dims(image, axis=0) \n",
    "\n",
    "        image_name = os.path.basename(image_path)\n",
    "        matches = re.search(self.pattern, image_name)\n",
    "        if matches is None:\n",
    "            print(f\"No match found for file: {image_name}\")\n",
    "            return None\n",
    "        variables = [float(matches.group(i)) for i in range(1, 10) if matches.group(i)]\n",
    "        epsnx = variables[0]  # epsnx value\n",
    "        alfa_x = variables[1]  # alfax value\n",
    "        return image, torch.tensor([epsnx, alfa_x])  # Returns epsnx, alfa x and betax as the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3799 422 1\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "image_dirs = [\"local-images-before-after-propagation-bw-shorter/2-param/\", \"local-images-before-after-propagation-bw-shorter/3-param/\"]\n",
    "image_files = [os.path.join(dir_path, name) \n",
    "               for dir_path in image_dirs \n",
    "               for name in sorted(os.listdir(dir_path))]\n",
    "\n",
    "total_size = len(image_files)\n",
    "train_prop = 0.90\n",
    "val_prop = 0.10\n",
    "\n",
    "train_size = int(train_prop * total_size)\n",
    "val_size = int(val_prop * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "print(train_size, val_size, test_size)\n",
    "\n",
    "# Split the dataset\n",
    "train_files = image_files[:train_size]\n",
    "val_files = image_files[train_size:train_size + val_size]\n",
    "test_files = image_files[train_size + val_size:]\n",
    "\n",
    "train_dataset = CustomDataset(train_files)\n",
    "val_dataset = CustomDataset(val_files)\n",
    "test_dataset = CustomDataset(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 3.5521\n",
      "Epoch [2/30], Loss: 4.2344\n",
      "Epoch [3/30], Loss: 8.2496\n",
      "Epoch [4/30], Loss: 4.2512\n",
      "Epoch [5/30], Loss: 4.0006\n",
      "Epoch [6/30], Loss: 6.4638\n",
      "Epoch [7/30], Loss: 3.4164\n",
      "Epoch [8/30], Loss: 4.2968\n",
      "Epoch [9/30], Loss: 3.2311\n",
      "Epoch [10/30], Loss: 3.0185\n",
      "Epoch [11/30], Loss: 3.2910\n",
      "Epoch [12/30], Loss: 4.2347\n",
      "Epoch [13/30], Loss: 8.8917\n",
      "Epoch [14/30], Loss: 3.4224\n",
      "Epoch [15/30], Loss: 0.4820\n",
      "Epoch [16/30], Loss: 8.2682\n",
      "Epoch [17/30], Loss: 6.6173\n",
      "Epoch [18/30], Loss: 5.1701\n",
      "Epoch [19/30], Loss: 6.9315\n",
      "Epoch [20/30], Loss: 2.0271\n",
      "Epoch [21/30], Loss: 2.5312\n",
      "Epoch [22/30], Loss: 7.8179\n",
      "Epoch [23/30], Loss: 1.6436\n",
      "Epoch [24/30], Loss: 2.0422\n",
      "Epoch [25/30], Loss: 7.0844\n",
      "Epoch [26/30], Loss: 6.5665\n",
      "Epoch [27/30], Loss: 2.6208\n",
      "Epoch [28/30], Loss: 3.8862\n",
      "Epoch [29/30], Loss: 7.5379\n",
      "Epoch [30/30], Loss: 2.5882\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "num_epochs = 30\n",
    "\n",
    "model = CNN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "total_steps = len(train_dataloader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{total_steps}], Loss: {loss.item():.4f}\")\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "# filename = f\"cnn_{NAME}_size{total_size}_train{train_prop}_val{val_prop}_bs{batch_size}_lr{learning_rate}_e{num_epochs}.pth\"\n",
    "filename = f\"cnn_{NAME}_bs{batch_size}_lr{learning_rate}_e{num_epochs}_trn{train_size}.pth\"\n",
    "torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with simple validation circuit\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "best_loss = np.inf\n",
    "saved_models = []\n",
    "for epoch in range(num_epochs):\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(val_dataloader): \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {val_loss.item():.4f}\")\n",
    "\n",
    "    # Check if this model is better than previous ones\n",
    "    if val_loss < best_loss or epoch % 10 == 0:  # save model every 10 epochs and if it performs better\n",
    "        best_loss = min(best_loss, val_loss)\n",
    "        filename = f\"cnn_{NAME}_bs{batch_size}_lr{learning_rate}_e{epoch+1}_trn{train_size}.pth\"\n",
    "        torch.save(model.state_dict(), filename)\n",
    "        saved_models.append(filename)\n",
    "        # Keep the best 2 models and delete the rest\n",
    "        if len(saved_models) > 2:\n",
    "            os.remove(saved_models.pop(0))  # delete oldest model\n",
    "\n",
    "print(f\"Best Validation Loss: {best_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with validation function (works worse)\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define your parameter grid\n",
    "param_grid = {\n",
    "    'batch_size': [4],\n",
    "    'learning_rate': [0.001],\n",
    "    'num_epochs': [300]\n",
    "}\n",
    "\n",
    "grid = ParameterGrid(param_grid)\n",
    "\n",
    "for params in grid:\n",
    "    batch_size = params['batch_size']\n",
    "    learning_rate = params['learning_rate']\n",
    "    num_epochs = params['num_epochs']\n",
    "\n",
    "    filename = f\"cnn_{NAME}_size{total_size}_train{train_prop}_val{val_prop}_bs{batch_size}_lr{learning_rate}_e{num_epochs}.pth\"\n",
    "\n",
    "    # If the model file already exists, skip this iteration\n",
    "    if os.path.isfile(filename):\n",
    "        print(f\"Model file {filename} already exists. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = CNN().to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    avg_loss_10_epochs = 0.0\n",
    "    avg_val_loss_10_epochs = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()  # Set the model to training mode\n",
    "\n",
    "        for images, labels in train_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        avg_loss_10_epochs += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            for val_images, val_labels in val_dataloader:\n",
    "                val_images = val_images.to(device)\n",
    "                val_labels = val_labels.to(device)\n",
    "                val_outputs = model(val_images)\n",
    "                val_loss = criterion(val_outputs, val_labels)\n",
    "                total_val_loss += val_loss.item()\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            print(f\"Val Loss: {val_loss.item():.4f}\")       \n",
    "        \n",
    "        # Print average training loss across the last 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            avg_loss_last_10_epochs = sum(losses[-10:]) / 10\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Average Train Loss (Last 10 epochs): {avg_loss_last_10_epochs:.4f}\")\n",
    "            avg_loss_10_epochs = 0.0\n",
    "\n",
    "        # Print average training loss across all epochs every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            avg_loss_all_epochs = sum(losses) / len(losses)\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Average Train Loss (All epochs): {avg_loss_all_epochs:.4f}\")\n",
    "\n",
    "    # Test\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        total_test_loss = 0\n",
    "        for test_images, test_labels in test_dataloader:\n",
    "            test_images = test_images.to(device)\n",
    "            test_labels = test_labels.to(device)\n",
    "            test_outputs = model(test_images)\n",
    "            test_loss = criterion(test_outputs, test_labels)\n",
    "            total_test_loss += test_loss.item()\n",
    "        avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_dataset, num_variables):\n",
    "    model.eval()\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    total_mae = torch.zeros(num_variables, device=device)\n",
    "    total_mape = torch.zeros(num_variables, device=device)\n",
    "    total_smape = torch.zeros(num_variables, device=device)\n",
    "    total_mse = torch.zeros(num_variables, device=device)\n",
    "    total_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            absolute_error = torch.abs(outputs - labels)\n",
    "            total_mae += absolute_error.sum(dim=0)\n",
    "\n",
    "            non_zero_mask = torch.abs(labels) > 1e-8\n",
    "            percentage_error = (absolute_error / torch.abs(labels)) * 100\n",
    "            total_mape += (percentage_error * non_zero_mask).sum(dim=0)\n",
    "\n",
    "            smape = 200.0 * torch.abs(outputs - labels) / (torch.abs(outputs) + torch.abs(labels) + torch.finfo(torch.float32).eps)\n",
    "            total_smape += smape.sum(dim=0)\n",
    "            \n",
    "            mse = (outputs - labels) ** 2\n",
    "            total_mse += mse.sum(dim=0)\n",
    "\n",
    "            total_count += labels.size(0)\n",
    "\n",
    "    mae = total_mae / total_count\n",
    "    mape = total_mape / total_count\n",
    "    smape = total_smape / total_count\n",
    "    rmse = torch.sqrt(total_mse / total_count)\n",
    "\n",
    "    return mae.cpu().numpy(), mape.cpu().numpy(), smape.cpu().numpy(), rmse.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: .\\cnn_3param-2xeverything-bw_bs4_lr0.001_e100.pth, Aggregate Score: 20.4264\n",
      "Mean Absolute Error: [ 0.16377206  0.6010109  12.177272  ]\n",
      "Mean Absolute Percentage Error: [58.97214   59.230194   5.8334346]\n",
      "Symmetric Mean Absolute Percentage Error: [42.6713    41.39358    5.8123317]\n",
      "Root Mean Square Error: [ 0.21665739  0.7982512  17.247149  ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RUN MODEL EVALUATION\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "# Load models and evaluate their performance\n",
    "model_dir = './'  # Specify ysour directory where models are saved\n",
    "\n",
    "model_performance = []\n",
    "\n",
    "# Load each model and evaluate it\n",
    "for model_file in glob.glob(model_dir + '/*.pth'):\n",
    "    # Load model\n",
    "    model = CNN()\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    model.to(device)\n",
    "\n",
    "    # Evaluate model\n",
    "    mae, mape, smape, rmse = evaluate_model(model, test_dataset, 2)\n",
    "    aggregate_score = np.mean([mae, mape, smape, rmse])\n",
    "    model_performance.append((model_file, mae, mape, smape, rmse, aggregate_score))\n",
    "\n",
    "# Sort models based on aggregate score\n",
    "model_performance.sort(key=lambda x: x[-1])\n",
    "\n",
    "# Print the performance of each model\n",
    "for model_info in model_performance:\n",
    "    model_file, mae, mape, smape, rmse, aggregate_score = model_info\n",
    "    print(f\"Model: {model_file}, Aggregate Score: {aggregate_score:.4f}\")\n",
    "    print(f\"Mean Absolute Error: {mae}\")\n",
    "    print(f\"Mean Absolute Percentage Error: {mape}\")\n",
    "    print(f\"Symmetric Mean Absolute Percentage Error: {smape}\")\n",
    "    print(f\"Root Mean Square Error: {rmse}\")\n",
    "    print()\n",
    "\n",
    "# Open the text document in write mode\n",
    "with open('.txt', 'w') as f:\n",
    "    # Print model performance in order\n",
    "    for model_info in model_performance:\n",
    "        model_file, mae, mape, smape, rmse, aggregate_score = model_info\n",
    "        f.write(f\"Model: {model_file}, Aggregate Score: {aggregate_score:.4f}\\n\")\n",
    "        for i in range(2):\n",
    "            f.write(f\"Metrics for prediction {i+1}:\\n\")\n",
    "            f.write(f\"Mean Absolute Error: {mae[i]:.4f}\\n\")\n",
    "            f.write(f\"Mean Absolute Percentage Error: {mape[i]:.2f}%\\n\")\n",
    "            f.write(f\"Symmetric Mean Absolute Percentage Error: {smape[i]:.2f}%\\n\")\n",
    "            f.write(f\"Root Mean Square Error: {rmse[i]:.4f}\\n\")\n",
    "        f.write(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
