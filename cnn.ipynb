{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def partition_images(base_dir, train_dir, test_dir, train_ratio):\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    all_images = os.listdir(base_dir)\n",
    "    random.shuffle(all_images)\n",
    "\n",
    "    train_count = int(len(all_images) * train_ratio)\n",
    "    train_images = all_images[:train_count]\n",
    "    test_images = all_images[train_count:]\n",
    "\n",
    "    for image in train_images:\n",
    "        shutil.copyfile(os.path.join(base_dir, image), os.path.join(train_dir, image))\n",
    "\n",
    "    for image in test_images:\n",
    "        shutil.copyfile(os.path.join(base_dir, image), os.path.join(test_dir, image))\n",
    "\n",
    "partition_images('images', 'train', 'test', 0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 147 * 147, 256)  # Adjusted input size\n",
    "        self.fc2 = nn.Linear(256, 2) # predicting two variables (alfa x and betax)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = sorted(os.listdir(image_dir))\n",
    "        self.pattern = r\"epsnx([\\d.-]+)_alfax([\\d.-]+)_betax([\\d.-]+)_epsny([\\d.-]+)_alfay([\\d.-]+)_betay([\\d.-]+)_epsnz([\\d.-]+)_alfaz([\\d.-]+)_betaz([\\d.-]+)\\.png\"\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.image_files[index]\n",
    "        image_path = os.path.join(self.image_dir, image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = self.transform(image)\n",
    "        matches = re.search(self.pattern, image_name)\n",
    "        variables = [float(matches.group(i)) for i in range(1, 10) if matches.group(i)]\n",
    "        alfa_x = variables[1] # alfax value\n",
    "        beta_x = variables[2] # betax value\n",
    "        return image, torch.tensor([alfa_x, beta_x]) # returns alfa x and betax as the labels\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# batch_size = 16\n",
    "# learning_rate = 0.001\n",
    "# num_epochs = 500\n",
    "\n",
    "# model = CNN().to(device)\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# image_dir = \"train\"\n",
    "# dataset = CustomDataset(image_dir)\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# total_steps = len(dataloader)\n",
    "# for epoch in range(num_epochs):\n",
    "#     for i, (images, labels) in enumerate(dataloader):\n",
    "#         images = images.to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{total_steps}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "#         if (i + 1) % 10 == 0:\n",
    "#             print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{total_steps}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# torch.save(model.state_dict(), \"cnn_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for prediction 1:\n",
      "Mean Absolute Error: 0.2733\n",
      "Mean Absolute Percentage Error: nan%\n",
      "Symmetric Mean Absolute Percentage Error: 24.68%\n",
      "Root Mean Square Error: 0.5499\n",
      "\n",
      "Metrics for prediction 2:\n",
      "Mean Absolute Error: 3.0604\n",
      "Mean Absolute Percentage Error: 1.16%\n",
      "Symmetric Mean Absolute Percentage Error: 1.17%\n",
      "Root Mean Square Error: 6.1382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, test_dir):\n",
    "    model.eval()\n",
    "    test_dataset = CustomDataset(test_dir)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    total_mae = torch.zeros(2, device=device)   # Added device argument\n",
    "    total_mape = torch.zeros(2, device=device)  # Added device argument\n",
    "    total_smape = torch.zeros(2, device=device) # Added device argument\n",
    "    total_mse = torch.zeros(2, device=device)   # Added device argument\n",
    "    total_count = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            absolute_error = torch.abs(outputs - labels)  # Absolute error\n",
    "            total_mae += absolute_error.sum(dim=0)\n",
    "\n",
    "            non_zero_mask = torch.abs(labels) > 1e-8  # Only calculate percentage for non-zero labels\n",
    "            percentage_error = (absolute_error / torch.abs(labels)) * 100  # Percentage error\n",
    "            total_mape += (percentage_error * non_zero_mask).sum(dim=0)\n",
    "\n",
    "            smape = 200.0 * torch.abs(outputs - labels) / (torch.abs(outputs) + torch.abs(labels) + torch.finfo(torch.float32).eps)\n",
    "            total_smape += smape.sum(dim=0)\n",
    "            \n",
    "            mse = (outputs - labels) ** 2  # Mean Square Error\n",
    "            total_mse += mse.sum(dim=0)\n",
    "\n",
    "            total_count += labels.size(0)  # number of samples\n",
    "\n",
    "    mae = total_mae / total_count\n",
    "    mape = total_mape / total_count\n",
    "    smape = total_smape / total_count\n",
    "    rmse = torch.sqrt(total_mse / total_count)\n",
    "\n",
    "    return mae.cpu().numpy(), mape.cpu().numpy(), smape.cpu().numpy(), rmse.cpu().numpy()  # Moved tensors to CPU and converted to numpy\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CNN()\n",
    "model.load_state_dict(torch.load(\"cnn_model.pth\"))\n",
    "model.to(device)\n",
    "\n",
    "mae, mape, smape, rmse = evaluate_model(model, \"test\")\n",
    "for i in range(2):\n",
    "    print(f\"Metrics for prediction {i+1}:\")\n",
    "    print(f\"Mean Absolute Error: {mae[i]:.4f}\")\n",
    "    print(f\"Mean Absolute Percentage Error: {mape[i]:.2f}%\")\n",
    "    print(f\"Symmetric Mean Absolute Percentage Error: {smape[i]:.2f}%\")\n",
    "    print(f\"Root Mean Square Error: {rmse[i]:.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted variables: [0.011563804000616074, 281.4032897949219]\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "\n",
    "model = CNN()\n",
    "model.load_state_dict(torch.load(\"cnn_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# using cv2 is gross but i like the transforms more\n",
    "image_path = \"test\\epsnx0.10_alfax-0.00_betax282.89_epsny0.10_alfay-0.55_betay170.00_epsnz5.00_alfaz0.10_betaz10.00.png\"\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image = transforms.ToTensor()(image)\n",
    "image = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(image)\n",
    "image = image.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "    predicted_variables = output.squeeze().tolist()\n",
    "\n",
    "print(\"Predicted variables:\", predicted_variables)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
