{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-PARAMETER SIDE_BY_SIDE MODEL \n",
    "NAME = \"3param-dbwd\"\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 197 * 98, 256)  # Adjusted input size\n",
    "        self.fc2 = nn.Linear(256, 3) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB for DOUBLE WIDE IMAGE\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_files):\n",
    "        self.image_files = image_files\n",
    "        self.pattern = r\"epsnx([\\d.-]+)_alfax([\\d.-]+)_betax([\\d.-]+)_epsny([\\d.-]+)_alfay([\\d.-]+)_betay([\\d.-]+)_epsnz([\\d.-]+)_alfaz([\\d.-]+)_betaz([\\d.-]+)_*[\\d]*\\.png\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_files[index]\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (394, 197)).astype(np.float32) / 255.0\n",
    "\n",
    "        # add dummy dim (1, x, x)\n",
    "        image = np.expand_dims(image, axis=0) \n",
    "\n",
    "        image_name = os.path.basename(image_path)\n",
    "        matches = re.search(self.pattern, image_name)\n",
    "        if matches is None:\n",
    "            print(f\"No match found for file: {image_name}\")\n",
    "            return None\n",
    "        variables = [float(matches.group(i)) for i in range(1, 10) if matches.group(i)]\n",
    "        epsnx = variables[0]  # epsnx value\n",
    "        alfa_x = variables[1]  # alfax value\n",
    "        beta_x = variables[2]  # betax value\n",
    "        return image, torch.tensor([epsnx, alfa_x, beta_x])  # Returns epsnx, alfa x and betax as the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB for SINGLE WIDE IMAGE\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_files):\n",
    "        self.image_files = image_files\n",
    "        self.pattern = r\"epsnx([\\d.-]+)_alfax([\\d.-]+)_betax([\\d.-]+)_epsny([\\d.-]+)_alfay([\\d.-]+)_betay([\\d.-]+)_epsnz([\\d.-]+)_alfaz([\\d.-]+)_betaz([\\d.-]+)_*[\\d]*\\.png\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_files[index]\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (294, 294)).astype(np.float32) / 255.0\n",
    "\n",
    "        # add dummy dim (1, x, x)\n",
    "        image = np.expand_dims(image, axis=0) \n",
    "\n",
    "        image_name = os.path.basename(image_path)\n",
    "        matches = re.search(self.pattern, image_name)\n",
    "        if matches is None:\n",
    "            print(f\"No match found for file: {image_name}\")\n",
    "            return None\n",
    "        variables = [float(matches.group(i)) for i in range(1, 10) if matches.group(i)]\n",
    "        epsnx = variables[0]  # epsnx value\n",
    "        alfa_x = variables[1]  # alfax value\n",
    "        beta_x = variables[2]  # betax value\n",
    "        return image, torch.tensor([epsnx, alfa_x, beta_x])  # Returns epsnx, alfa x and betax as the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3_PARAM MODEL\n",
    "NAME = \"3param-2xeverything-bw\"\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 147 * 147, 256)  # Adjust this if needed\n",
    "        self.fc2 = nn.Linear(256, 3)  # Now predicting three variables\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2_PARAM SIMPLE MODEL SINGLE IMAGE\n",
    "NAME = \"2param-bw-sgwd\"\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)  # Input channel changed to 1\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 147 * 147, 256)  # Adjust this if needed\n",
    "        self.fc2 = nn.Linear(256, 2)  # Now predicting three variables\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2_PARAM DATASET\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = sorted(os.listdir(image_dir))\n",
    "        self.pattern = r\"epsnx([\\d.-]+)_alfax([\\d.-]+)_betax([\\d.-]+)_epsny([\\d.-]+)_alfay([\\d.-]+)_betay([\\d.-]+)_epsnz([\\d.-]+)_alfaz([\\d.-]+)_betaz([\\d.-]+)_*[\\d]*\\.png\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.image_files[index]\n",
    "        image_path = os.path.join(self.image_dir, image_name)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Reading image as grayscale\n",
    "        #\n",
    "        image = cv2.resize(image, (294, 294))\n",
    "        #\n",
    "        matches = re.search(self.pattern, image_name)\n",
    "        if matches is None:\n",
    "            print(f\"No match found for file: {image_name}\")\n",
    "            return None\n",
    "        variables = [float(matches.group(i)) for i in range(1, 10) if matches.group(i)]\n",
    "        alfa_x = variables[1]  # alfax value\n",
    "        beta_x = variables[2]  # betax value\n",
    "        return image, torch.tensor([alfa_x, beta_x])  # Returns epsnx, alfa x and betax as the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3_PARAM DATASET\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = sorted(os.listdir(image_dir))\n",
    "        self.pattern = r\"epsnx([\\d.-]+)_alfax([\\d.-]+)_betax([\\d.-]+)_epsny([\\d.-]+)_alfay([\\d.-]+)_betay([\\d.-]+)_epsnz([\\d.-]+)_alfaz([\\d.-]+)_betaz([\\d.-]+)_*[\\d]*\\.png\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.image_files[index]\n",
    "        image_path = os.path.join(self.image_dir, image_name)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        #\n",
    "        image = cv2.resize(image, (294, 294))\n",
    "        #\n",
    "        matches = re.search(self.pattern, image_name)\n",
    "        if matches is None:\n",
    "            print(f\"No match found for file: {image_name}\")\n",
    "            return None\n",
    "        variables = [float(matches.group(i)) for i in range(1, 10) if matches.group(i)]\n",
    "        epsnx = variables[0]  # epsnx value\n",
    "        alfa_x = variables[1]  # alfax value\n",
    "        beta_x = variables[2]  # betax value\n",
    "        return image, torch.tensor([epsnx, alfa_x, beta_x])  # Returns epsnx, alfa x and betax as the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6_PARAM DATASET\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = sorted(os.listdir(image_dir))\n",
    "        self.pattern = r\"epsnx([\\d.-]+)_alfax([\\d.-]+)_betax([\\d.-]+)_epsny([\\d.-]+)_alfay([\\d.-]+)_betay([\\d.-]+)_epsnz([\\d.-]+)_alfaz([\\d.-]+)_betaz([\\d.-]+)_*[\\d]*\\.png\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.image_files[index]\n",
    "        image_path = os.path.join(self.image_dir, image_name)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        #\n",
    "        image = cv2.resize(image, (294, 294))\n",
    "        #\n",
    "        matches = re.search(self.pattern, image_name)\n",
    "        if matches is None:\n",
    "            print(f\"No match found for file: {image_name}\")\n",
    "            return None\n",
    "        variables = [float(matches.group(i)) for i in range(1, 10) if matches.group(i)]\n",
    "        epsnx = variables[0]  # epsnx value\n",
    "        alfa_x = variables[1]  # alfax value\n",
    "        beta_x = variables[2]  # betax value\n",
    "        epsny = variables[3]  # epsnx value\n",
    "        alfa_y = variables[4]  # alfax value\n",
    "        beta_y = variables[5]  # betax value\n",
    "        return image, torch.tensor([epsnx, alfa_x, beta_x, epsny, alfa_y, beta_y])  # Returns epsnx, alfa x and betax as the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doublewides\n",
    "def __getitem__(self, index):\n",
    "        image_name = self.image_files[index]\n",
    "        image_path = os.path.join(self.image_dir, image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (394, 197))\n",
    "        matches = re.search(self.pattern, image_name)\n",
    "        variables = [float(matches.group(i)) for i in range(1, 10) if matches.group(i)]\n",
    "        emm_x = variables[0] # alfax value\n",
    "        alfa_x = variables[1] # alfax value\n",
    "        beta_x = variables[2] # betax value\n",
    "        return image, torch.tensor([emm_x, alfa_x, beta_x]) # returns alfa x and betax as the labels"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
